{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed libraries. Load needed objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ad hoc library\n",
    "from sbhandler import * \n",
    "\n",
    "# Data Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning Framework\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Store and Load Objects\n",
    "from pickle import load, dump  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembly Matrices (pd.DataFrame objects)\n",
    "RFP_LIST = load( open('pickle/v1rfp.pickle', 'rb'))\n",
    "BFP_LIST = load( open('pickle/v1bfp.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features to generate for Extended Logistic Regression Model\n",
    "- Type (2):      &emsp;     &emsp;       &emsp; &emsp; &emsp; &emsp;  isSNP, isInsertion, (isDeletion ~ implied by other two)\n",
    "- Length (1):    &emsp;  &emsp;  &emsp; &emsp;      &emsp;   &nbsp;        isSingle, (isMulti)\n",
    "- Near another Indel (1):   &emsp;  isNear, (isFar)\n",
    "- Neighbors (1):        &emsp;   &emsp; &ensp; &nbsp;   &emsp;   isConcord, (isDiscord)\n",
    "- Observed Error Rate [5]:  &nbsp;    Map Phred Q Score to SNP/Indel (1-epsilon) for the Nucleotide *-OR-* (epsilon * conditional error)\n",
    "    - Multiply instances\n",
    "- Count [5]: &emsp; &emsp; &emsp; &emsp; &emsp; &ensp; Explicit read count of each nuc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Column: Variation Type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov(df): return int((len(df.columns)-4-4)/2)\n",
    "\n",
    "def pd_reads_truncater(df, list_reads):\n",
    "    # Removes meaningless indels that only arise from start, end alignment\n",
    "    ret_list = []\n",
    "\n",
    "    for read in list_reads:\n",
    "        nan_indel_mask = read[read != 45]\n",
    "        first_valid = nan_indel_mask.first_valid_index()\n",
    "        last_valid = nan_indel_mask.last_valid_index()\n",
    "        ret_list.append( (first_valid, last_valid) )\n",
    "        # Replace all 45's before and after the idx tuple with 1\n",
    "        if first_valid is not None and first_valid!= df.index[0]:\n",
    "            read.loc[:first_valid] = 1 # start and excluding\n",
    "        if last_valid is not None and last_valid != df.index[-1]:\n",
    "            read.loc[last_valid+1:] = 1 # past and end\n",
    "            \n",
    "    return ret_list\n",
    "\n",
    "def add_variation_type(df, cov):\n",
    "    \"\"\"Adds Variation Type: Assumes `is_indel` column exists\n",
    "\n",
    "    Filters (conditional) by at least a single 45 instance in a row.\n",
    "    \n",
    "    If: ground truth is a 45 (-) -> It's an insertion.\n",
    "    Else: It's a deletion.\n",
    "    Args:\n",
    "        df (DataFrame): RFP or BFP\n",
    "        cov (int): coverage; no. of reads\n",
    "        Return: adds `is_snip` and `is_ins` boolean column\n",
    "    \"\"\"\n",
    "    df['is_ins'] = np.where( df[['target', 'is_indel']].eq([45, True], axis=1).all(axis=1), True, False)\n",
    "\n",
    "    def check_row_variation(df, cov):\n",
    "        if cov == 1:\n",
    "            reads = df.iloc[:, 1]\n",
    "            targ = df.iloc[:, 0]\n",
    "            return (reads != targ)\n",
    "        else:\n",
    "            reads = df.iloc[:, 1:cov+1]\n",
    "            targ = df.iloc[:, 0]\n",
    "            return ( reads.sum(axis=1) != (targ*cov))\n",
    "    df['is_snp'] = np.where( df['is_indel'] == False, check_row_variation(df, cov), False)\n",
    "    \n",
    "    # Double conditional\n",
    "    # First... check if its an indel -> immediately goes to False\n",
    "    # Then... check if the target and at least one read disagree ->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Length Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isSingleSNP(df, idx):\n",
    "    pass\n",
    "\n",
    "def isSingleDel(df, cov, idx, adjust, rfp=False): # Checks if read has only one indel.\n",
    "    # Assumes it's a del row.\n",
    "    if rfp: # Only difference is use of .loc instead of .iloc\n",
    "        def check_del_left(df, idx, cov):\n",
    "            if idx == df.index[0]: return False\n",
    "            return (df.iloc[idx-adjust-1, 1:cov+1] == 45).any()\n",
    "        def check_del_right(df, idx, cov):\n",
    "            if idx == df.index[-1]: return False\n",
    "            return ((df.iloc[idx-adjust+1, 1:cov+1] == 45).any())\n",
    "        # print(idx, df.index.name)\n",
    "        # print(df.iloc[idx-adjust, -1])\n",
    "        # print(check_del_right(df, idx, cov))\n",
    "        # print(check_del_left(df, idx, cov))\n",
    "        df.iloc[idx-adjust, -1] = False if ( check_del_right(df, idx, cov) and check_del_left(df, idx, cov)) else True\n",
    "        # print(idx, df.index.name)\n",
    "    else:\n",
    "        def check_del_left(df, idx, cov):\n",
    "            if idx == 0: return False\n",
    "            return (df.iloc[idx-1, 1:cov+1] == 45).any()\n",
    "        def check_del_right(df, idx, cov):\n",
    "            if idx == len(df) - 1: return False\n",
    "            return ((df.iloc[idx+1, 1:cov+1] == 45).any())\n",
    "        df.iloc[idx, -1] = False if ( check_del_right(df, idx, cov) and check_del_left(df, idx, cov)) else True\n",
    "    # isMulti if a single 45 is present left or right.\n",
    "    \n",
    "def isSingleIns(df, idx, adjust, rfp=False): # Checks if target has only one indel.\n",
    "    if rfp:\n",
    "        def check_right(df, idx):\n",
    "            if idx == df.index[-1]: return False\n",
    "            return (df.iloc[idx-adjust+1, 0] == 45)\n",
    "        def check_left(df, idx):\n",
    "            if idx == df.index[0]: return False\n",
    "            return df.iloc[idx-adjust-1, 0] == 45\n",
    "        # print(idx, df.index.name)\n",
    "        df.iloc[idx-adjust, -1] = False if (check_right(df, idx) and check_left(df, idx)) else True\n",
    "        # print(idx, df.index.name)\n",
    "    else:\n",
    "        def check_right(df, idx):\n",
    "            if idx == len(df) - 1: return False\n",
    "            return (df.iloc[idx+1, 0] == 45)\n",
    "        def check_left(df, idx):\n",
    "            if idx == 0: return False\n",
    "            return (df.iloc[idx-1, 0] == 45)\n",
    "        # print(idx)\n",
    "        df.iloc[idx, -1] = False if (check_right(df, idx) and check_left(df, idx)) else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variation_length(df, cov, rfp=False):\n",
    "    df['is_single'] = [True for _ in range(len(df))]\n",
    "    adjust = df.index[0]\n",
    "\n",
    "    dels = df.iloc[np.where(( df[['is_indel', 'is_ins']] == [True, False] ).all(axis=1) == True)[0], :]\n",
    "    to_check = dels.index.to_list()\n",
    "    if not to_check == []:\n",
    "        for i in to_check:\n",
    "            isSingleDel( df, cov, i, adjust, rfp=rfp)\n",
    "\n",
    "    ins = df.iloc[np.where((df[['is_indel', 'is_ins']] == [True, True]).all(axis=1) == True)[0], :]\n",
    "    to_check = ins.index.to_list()\n",
    "    if not to_check:\n",
    "        for i in to_check:\n",
    "            isSingleIns(df, i, adjust, rfp=rfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Engineered Features to RFP and BFP pd.DataFrame objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df, cov, indel_parse=False, rfp=False):\n",
    "    if indel_parse:\n",
    "        nan_mask = df.iloc[:, 0:cov+1][df!=45]\n",
    "        df['is_indel'] = np.where(nan_mask.count(axis = 1) == cov+1, False, True) #cov + 1 because targ/contig included\n",
    "        \n",
    "    # isSNP, isIns, isDel\n",
    "    add_variation_type(df, cov)\n",
    "    \n",
    "    # isSingle, isMulti\n",
    "    add_variation_length(df, cov, rfp=rfp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_progress(n, each=False):\n",
    "    if each:\n",
    "        print(n, end=\"\\r\")\n",
    "    else:\n",
    "        if (n % 3551 == 0): print(f'{n / 355104:.0%}', end='\\r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355103\r"
     ]
    }
   ],
   "source": [
    "for n, bfp in enumerate(BFP_LIST):\n",
    "    if bfp.empty: continue\n",
    "    get_progress(n, each=True)\n",
    "    add_features(bfp, get_cov(bfp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle/v2bfp.pickle', 'wb') as f:\n",
    "    dump(BFP_LIST, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355103\r"
     ]
    }
   ],
   "source": [
    "for n, rfp in enumerate(RFP_LIST):\n",
    "    if rfp.empty: continue\n",
    "    get_progress(n, each=True)\n",
    "    \n",
    "    add_features(rfp, get_cov(rfp), rfp=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle/v2rfp.pickle', 'wb') as f:\n",
    "    dump(RFP_LIST, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, bfp in enumerate(umm):\n",
    "    if bfp.empty: continue\n",
    "    a = (bfp[bfp['is_snp'] == True])\n",
    "    b = (bfp[bfp['mutations'] == 120])\n",
    "    if not b.empty:\n",
    "        if not a.empty:\n",
    "            print(bfp.index.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           target  read1  q1  changes  contig  mutations  is_indel\n",
      "01B--1046                                                         \n",
      "259            84     65  51       32      65        120     False\n",
      "702            45     67  91       32      67        120      True\n"
     ]
    }
   ],
   "source": [
    "# for bfp in BFP_LIST[1000:]:\n",
    "#     if bfp.empty: continue\n",
    "#     find = bfp[bfp['mutations'] != 32]\n",
    "#     if find.empty: continue\n",
    "#     print(find)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to facilitate feature-type filtering -> will be used to grab specific rows for training\n",
    "def pd_filter(df, columns, conditions, all=True):\n",
    "    columns_to_filter_by = df[columns]\n",
    "    if all:\n",
    "        return df.iloc[np.where( (columns_to_filter_by == conditions).all(axis=1))[0]]\n",
    "    else:\n",
    "        return df.iloc[np.where( (columns_to_filter_by == conditions).any(axis=1))[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_ASSEMBLY_MATRICES = 355104\n",
    "TOTAL_SAMPLES = TOTAL_ASSEMBLY_MATRICES * 50\n",
    "\n",
    "PERCENT_RED = 0.4\n",
    "PERCENT_BLUE = 0.6\n",
    "\n",
    "PERCENT_SNP = 0.3\n",
    "PERCENT_INS = 0.4\n",
    "PERCENT_DEL = 0.3\n",
    "PERCENT_REGULAR = 0.1\n",
    "\n",
    "# To change as more features are added\n",
    "SAMPLE_SHAPE = (14)\n",
    "LABEL_SHAPE = (5)\n",
    "\n",
    "COUNT_MAPPING = {65 : 0, 67 : 0, 71 : 2, 84: 3, 45 : 4,}\n",
    "\n",
    "PROB_MAPPING = dict(zip([65, 67, 71, 84, 45], [5, 6, 7, 8, 9]))\n",
    "\n",
    "CATEGORY_MAPPING = dict(zip(['is_snp', 'is_ins', 'is_single', 'is_rfp'], [0, 1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query by Quality Score... then query by ground truth and read.\n",
    "CEM_INDELS = load( open('pickle/cem_indels_tensor.pickle', 'rb'))\n",
    "CEM_SNIPS = load( open('pickle/cem_snips_tensor.pickle', 'rb'))\n",
    "\n",
    "QADJ_INDELS = np.zeros( (5, 94) )\n",
    "QADJ_SNIPS = np.zeros( (4, 94) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_indels = load( open('pickle/v1TrackingIndelswRFP.pickle', 'rb'))\n",
    "tracking_snips = load( open('pickle/v1TrackingSnipswRFP.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuc_hot_encode(nuc):\n",
    "    dict = {'A' : 0, 'C': 1, 'G' : 2, 'T' : 3, '-' : 4}\n",
    "    return dict.get(nuc)\n",
    "\n",
    "def to_epsilon(tracking, nuc, storage):\n",
    "    focus = tracking[nuc]\n",
    "    to_add = []\n",
    "    for q, i in focus.items():\n",
    "        print(i)\n",
    "        if np.sum(i == 0): to_add.append(None)\n",
    "        else:\n",
    "            print(np.sum(i[1:]))\n",
    "            to_add.append(np.sum(i[1:])/np.sum(i))\n",
    "    storage[nuc_hot_encode(nuc)] = to_add\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nuc in ['A', 'C', 'G','T', '-']:\n",
    "    to_epsilon(tracking_indels, nuc, QADJ_INDELS)\n",
    "for nuc in ['A', 'C', 'G', 'T']:\n",
    "    to_epsilon(tracking_snips, nuc, QADJ_SNIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHRED to ERROR RATE\n",
    "def convert_to_epsilon(nuc, zero_shifted_quality, indel=True):\n",
    "    database = QADJ_INDELS if indel else QADJ_SNIPS\n",
    "    return database[nuc][zero_shifted_quality]\n",
    "    \n",
    "# PHRED to CONDITIONAL SEQ ERROR\n",
    "def convert_to_cond_seq_error(nuc, ground_truth, zero_shifted_quality, indel=True):\n",
    "    database = CEM_INDELS if indel else CEM_SNIPS\n",
    "    cond_seq_error = database[zero_shifted_quality][PROB_MAPPING[nuc], PROB_MAPPING[ground_truth]]\n",
    "    return cond_seq_error * convert_to_epsilon(nuc, zero_shifted_quality, indel=indel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_df_run(df, all_samples, all_labels, reads_max, rfp=False, enforce_cov = False, cov_min=4, cov_max=20):\n",
    "    cov = get_cov(df)\n",
    "    if enforce_cov and (cov < cov_min or cov > cov_max): return\n",
    "\n",
    "    reads_idxs = [i for i in range(1, cov+1)]\n",
    "    \n",
    "    if cov > reads_max: \n",
    "        reads_to_use = np.random.sample(reads_idxs, reads_max)\n",
    "    else:\n",
    "        reads_to_use = reads_idxs\n",
    "        \n",
    "    # Get SNPs only\n",
    "    snps = pd_filter(df, 'is_snp', True)\n",
    "    \n",
    "    # Get indels only\n",
    "    ins = pd_filter(df, 'is_ins', True)\n",
    "    dels = pd_filter(df, ['is_indel', 'is_ins'], [True, False])\n",
    "    \n",
    "    # Get regulars?\n",
    "    regs = pd_filter(df, ['is_indel', 'is_snp'], [False, False])\n",
    "    \n",
    "    def extend_data(s, l):\n",
    "        all_samples.extend(s)\n",
    "        all_labels.extend(l)\n",
    "    \n",
    "    # Actually update it\n",
    "    if count_snp < max_snp:\n",
    "        s, l = sample_label_generator(df, snps, cov, reads_to_use, all_samples, all_labels, snps=True, rfp=rfp)\n",
    "        count_snp += len(l)\n",
    "        extend_data(s, l)\n",
    "    \n",
    "    if count_ins < max_ins:\n",
    "        s, l = sample_label_generator(df, ins, cov, reads_to_use, all_samples, all_labels, ins=True, rfp=rfp)\n",
    "        count_ins += len(l)\n",
    "        extend_data(s, l)\n",
    "    \n",
    "    if count_del < max_del:\n",
    "        s, l = sample_label_generator(df, dels, cov, reads_to_use, all_samples, all_labels,rfp=rfp)\n",
    "        count_del += len(l)\n",
    "        extend_data(s, l)\n",
    "    \n",
    "    if count_reg < max_reg:\n",
    "        s, l = sample_label_generator(df, regs, cov, reads_to_use, all_samples, all_labels, snps=True, rfp=rfp)\n",
    "        count_reg += len(l)\n",
    "        extend_data(s, l)\n",
    "\n",
    "def sample_label_generator(df, filtered_data, cov, reads_to_use, rfp=False, snps=False, ins=False):\n",
    "    samples = []\n",
    "    labels = []\n",
    "    \n",
    "    idx_iter = len(filtered_data)\n",
    "    \n",
    "    for i in range(idx_iter):\n",
    "        sample = torch.empty(SAMPLE_SHAPE)\n",
    "        label = torch.zeros(LABEL_SHAPE)\n",
    "        count = np.zeros(5)\n",
    "        prob = np.ones(5)\n",
    "        \n",
    "        if snps:\n",
    "            category = np.array([1, 0, 0, 1]) if rfp else np.array([1, 0, 0, 0])\n",
    "        elif ins:\n",
    "            category = np.array([0, 1, 0, 1]) if rfp else np.array([0, 1, 0, 0])\n",
    "        else:\n",
    "            category = np.array([0, 0, 0, 1]) if rfp else np.array([0, 0, 0, 0])\n",
    "        \n",
    "        # Row by row...\n",
    "        ground = df['target'].iloc[i]\n",
    "        truth = df['contig'].iloc[i] if rfp else ground\n",
    "            \n",
    "        for r in reads_to_use:\n",
    "            nuc = df[f'read{r}'].iloc[i]\n",
    "            quality = df[f'q{r}'].iloc[i]\n",
    "            if nuc == ground:\n",
    "                prob[PROB_MAPPING.get(nuc)] *= (1 - convert_to_epsilon('snp', nuc, quality) )\n",
    "            else: \n",
    "                prob[PROB_MAPPING.get(nuc)] *= convert_to_epsilon('snp', nuc, quality) * convert_to_cond_seq_error('snp', nuc, ground, quality)\n",
    "            count[PROB_MAPPING.get(nuc)] += 1\n",
    "            \n",
    "        if df['is_single'].iloc[i] is True:\n",
    "            category[CATEGORY_MAPPING.get('is_single')] = 1\n",
    "            \n",
    "        # Update sample, label\n",
    "        sample[0:5] = count\n",
    "        sample[5:10] = prob\n",
    "        sample[10:14] = category\n",
    "        \n",
    "        label[PROB_MAPPING.get(truth)] = 1\n",
    "        \n",
    "        samples.append(sample)\n",
    "        labels.append(label)\n",
    "        \n",
    "    return samples, labels\n",
    "\n",
    "def get_data(df_list, rfp=False, enforce_cov=False, cov_min=4, cov_max=20, reads_max=3, total=TOTAL_SAMPLES, multiple_sizes=False, multiple_sampling=False, random_select=False):\n",
    "    all_samples = []\n",
    "    all_labels = []\n",
    "    \n",
    "    percent_of_total = PERCENT_BLUE\n",
    "    if rfp: percent_of_total = PERCENT_RED\n",
    "    \n",
    "    size = percent_of_total * total\n",
    "    one_percent = 0.01 * size\n",
    "    \n",
    "    max_snp = PERCENT_SNP * total\n",
    "    max_ins = PERCENT_INS * total\n",
    "    max_del = PERCENT_DEL * total\n",
    "    max_reg = PERCENT_REGULAR * total\n",
    "    \n",
    "    count_snp, count_ins, count_del, count_reg = 0, 0, 0, 0\n",
    "    \n",
    "    if random_select:\n",
    "        random_idxs = np.random.permutation(TOTAL_ASSEMBLY_MATRICES)\n",
    "        \n",
    "        for n, idx in enumerate(random_idxs):\n",
    "            get_progress(n, each=True)\n",
    "            df = df_list[idx]\n",
    "            if df.empty: continue\n",
    "            \n",
    "            single_df_run(df, all_samples, all_labels, reads_max)\n",
    "    else:\n",
    "        for n, df in enumerate(df_list):\n",
    "            get_progress(n, each=True)\n",
    "            if df.empty: continue\n",
    "            \n",
    "            single_df_run(df, all_samples, all_labels, reads_max)\n",
    "            \n",
    "    return all_samples, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, labels = get_data(BFP_LIST, random_select=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No axis named 1 for object type Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/venv/lib/python3.8/site-packages/pandas/core/generic.py:550\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_AXIS_TO_AXIS_NUMBER[axis]\n\u001b[1;32m    551\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/neurotoolbox/Desktop/David/mutalib/features.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=0'>1</a>\u001b[0m train_rx, train_ry \u001b[39m=\u001b[39m get_data(RFP_LIST, rfp\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, enforce_cov\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, cov_min\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, cov_max\u001b[39m=\u001b[39;49m\u001b[39m9\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=1'>2</a>\u001b[0m train_bx, train_by \u001b[39m=\u001b[39m get_data(BFP_LIST)\n",
      "\u001b[1;32m/home/neurotoolbox/Desktop/David/mutalib/features.ipynb Cell 30\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(df_list, rfp, enforce_cov, cov_min, cov_max, reads_max, total, multiple_sizes, multiple_sampling, random_select)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=121'>122</a>\u001b[0m         get_progress(n, each\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=122'>123</a>\u001b[0m         \u001b[39mif\u001b[39;00m df\u001b[39m.\u001b[39mempty: \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=124'>125</a>\u001b[0m         single_df_run(df, all_samples, all_labels, reads_max)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=126'>127</a>\u001b[0m \u001b[39mreturn\u001b[39;00m all_samples, all_labels\n",
      "\u001b[1;32m/home/neurotoolbox/Desktop/David/mutalib/features.ipynb Cell 30\u001b[0m in \u001b[0;36msingle_df_run\u001b[0;34m(df, all_samples, all_labels, reads_max, rfp, enforce_cov, cov_min, cov_max)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=9'>10</a>\u001b[0m     reads_to_use \u001b[39m=\u001b[39m reads_idxs\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=11'>12</a>\u001b[0m \u001b[39m# Get SNPs only\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=12'>13</a>\u001b[0m snps \u001b[39m=\u001b[39m pd_filter(df, \u001b[39m'\u001b[39;49m\u001b[39mis_snp\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=14'>15</a>\u001b[0m \u001b[39m# Get indels only\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=15'>16</a>\u001b[0m ins \u001b[39m=\u001b[39m pd_filter(df, \u001b[39m'\u001b[39m\u001b[39mis_ins\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/home/neurotoolbox/Desktop/David/mutalib/features.ipynb Cell 30\u001b[0m in \u001b[0;36mpd_filter\u001b[0;34m(df, columns, conditions, all)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=2'>3</a>\u001b[0m columns_to_filter_by \u001b[39m=\u001b[39m df[columns]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39miloc[np\u001b[39m.\u001b[39mwhere( (columns_to_filter_by \u001b[39m==\u001b[39;49m conditions)\u001b[39m.\u001b[39;49mall(axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))[\u001b[39m0\u001b[39m]]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=5'>6</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/neurotoolbox/Desktop/David/mutalib/features.ipynb#ch0000045?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39miloc[np\u001b[39m.\u001b[39mwhere( (columns_to_filter_by \u001b[39m==\u001b[39m conditions)\u001b[39m.\u001b[39many(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m~/.virtualenvs/venv/lib/python3.8/site-packages/pandas/core/generic.py:10899\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.all\u001b[0;34m(self, axis, bool_only, skipna, level, **kwargs)\u001b[0m\n\u001b[1;32m  10888\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m  10889\u001b[0m     _bool_doc,\n\u001b[1;32m  10890\u001b[0m     desc\u001b[39m=\u001b[39m_all_desc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10897\u001b[0m )\n\u001b[1;32m  10898\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mself\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, bool_only\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, skipna\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, level\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m> 10899\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39;49mall(\u001b[39mself\u001b[39;49m, axis, bool_only, skipna, level, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/venv/lib/python3.8/site-packages/pandas/core/generic.py:10471\u001b[0m, in \u001b[0;36mNDFrame.all\u001b[0;34m(self, axis, bool_only, skipna, level, **kwargs)\u001b[0m\n\u001b[1;32m  10463\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m  10464\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  10465\u001b[0m     axis: Axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10469\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  10470\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m bool_t:\n\u001b[0;32m> 10471\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_logical_func(\n\u001b[1;32m  10472\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mall\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnanall, axis, bool_only, skipna, level, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m  10473\u001b[0m     )\n",
      "File \u001b[0;32m~/.virtualenvs/venv/lib/python3.8/site-packages/pandas/core/generic.py:10442\u001b[0m, in \u001b[0;36mNDFrame._logical_func\u001b[0;34m(self, name, func, axis, bool_only, skipna, level, **kwargs)\u001b[0m\n\u001b[1;32m  10439\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bool_data()\n\u001b[1;32m  10440\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_reduce_axis1(name, func, skipna\u001b[39m=\u001b[39mskipna)\n\u001b[0;32m> 10442\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[1;32m  10443\u001b[0m     func,\n\u001b[1;32m  10444\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m  10445\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m  10446\u001b[0m     skipna\u001b[39m=\u001b[39;49mskipna,\n\u001b[1;32m  10447\u001b[0m     numeric_only\u001b[39m=\u001b[39;49mbool_only,\n\u001b[1;32m  10448\u001b[0m     filter_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbool\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m  10449\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/venv/lib/python3.8/site-packages/pandas/core/series.py:4455\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4452\u001b[0m delegate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[1;32m   4454\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4455\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_axis_number(axis)\n\u001b[1;32m   4457\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delegate, ExtensionArray):\n\u001b[1;32m   4458\u001b[0m     \u001b[39m# dispatch to ExtensionArray interface\u001b[39;00m\n\u001b[1;32m   4459\u001b[0m     \u001b[39mreturn\u001b[39;00m delegate\u001b[39m.\u001b[39m_reduce(name, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/.virtualenvs/venv/lib/python3.8/site-packages/pandas/core/generic.py:552\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_AXIS_TO_AXIS_NUMBER[axis]\n\u001b[1;32m    551\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m--> 552\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo axis named \u001b[39m\u001b[39m{\u001b[39;00maxis\u001b[39m}\u001b[39;00m\u001b[39m for object type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No axis named 1 for object type Series"
     ]
    }
   ],
   "source": [
    "train_rx, train_ry = get_data(RFP_LIST, rfp=True, enforce_cov=True, cov_min=4, cov_max=9)\n",
    "train_bx, train_by = get_data(BFP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rx, test_ry = get_data(RFP_LIST, rfp=True, enforce_cov=True, cov_min=10)\n",
    "test_bx, test_by = get_data(BFP_LIST, reads_max=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e45b5fe9540dcae422003c6a552f47067b28c6171ef36dc1ede64a9e99e7c78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
