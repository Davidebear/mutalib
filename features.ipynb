{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed libraries. Load needed objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ad hoc library\n",
    "from sbhandler import * \n",
    "def get_cov(df): return int((len(df.columns)-4)/2)\n",
    "\n",
    "# Data Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning Framework\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Store and Load Objects\n",
    "from pickle import load, dump  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembly Matrices (pd.DataFrame objects)\n",
    "# RFP_LIST = load( open('pickle/v1rfp.pickle', 'rb'))\n",
    "BFP_LIST = load( open('pickle/v1bfp.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features to generate for Extended Logistic Regression Model\n",
    "- Type (2):      &emsp;     &emsp;       &emsp; &emsp; &emsp; &emsp;  isSNP, isInsertion, (isDeletion ~ implied by other two)\n",
    "- Length (1):    &emsp;  &emsp;  &emsp; &emsp;      &emsp;   &nbsp;        isSingle, (isMulti)\n",
    "- Near another Indel (1):   &emsp;  isNear, (isFar)\n",
    "- Neighbors (1):        &emsp;   &emsp; &ensp; &nbsp;   &emsp;   isConcord, (isDiscord)\n",
    "- Observed Error Rate [5]:  &nbsp;    Map Phred Q Score to SNP/Indel (1-epsilon) for the Nucleotide *-OR-* (epsilon * conditional error)\n",
    "    - Multiply instances\n",
    "- Count [5]: &emsp; &emsp; &emsp; &emsp; &emsp; &ensp; Explicit read count of each nuc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Column: Variation Type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov(df): return int((len(df.columns)-4)/2)\n",
    "\n",
    "def pd_reads_truncater(df, list_reads):\n",
    "    # Removes meaningless indels that only arise from start, end alignment\n",
    "    ret_list = []\n",
    "\n",
    "    for read in list_reads:\n",
    "        nan_indel_mask = read[read != 45]\n",
    "        first_valid = nan_indel_mask.first_valid_index()\n",
    "        last_valid = nan_indel_mask.last_valid_index()\n",
    "        ret_list.append( (first_valid, last_valid) )\n",
    "        # Replace all 45's before and after the idx tuple with 1\n",
    "        if first_valid is not None and first_valid!= df.index[0]:\n",
    "            read.loc[:first_valid] = 1 # start and excluding\n",
    "        if last_valid is not None and last_valid != df.index[-1]:\n",
    "            read.loc[last_valid+1:] = 1 # past and end\n",
    "            \n",
    "    return ret_list\n",
    "\n",
    "def add_variation_type(df, cov):\n",
    "    \"\"\"Adds Variation Type: Assumes `is_indel` column exists\n",
    "\n",
    "    Filters (conditional) by at least a single 45 instance in a row.\n",
    "    \n",
    "    If: ground truth is a 45 (-) -> It's an insertion.\n",
    "    Else: It's a deletion.\n",
    "    Args:\n",
    "        df (DataFrame): RFP or BFP\n",
    "        cov (int): coverage; no. of reads\n",
    "        Return: adds `is_snip` and `is_ins` boolean column\n",
    "    \"\"\"\n",
    "    df['is_ins'] = np.where( df[['target', 'is_indel']].eq([45, True], axis=1).all(axis=1), True, False)\n",
    "\n",
    "    def check_row_variation(df, cov):\n",
    "        left = df.iloc[:, 1:cov+1]\n",
    "        right = df.iloc[:, 0]\n",
    "        left, right = left.align(right, axis=1, copy=False)\n",
    "        return np.where( (left != right).any(axis=1)), True, False)\n",
    "    \n",
    "    df['is_snp'] = np.where( df['is_indel'] == False, check_row_variation(df, cov), False)\n",
    "    # Double conditional\n",
    "    # First... check if its an indel -> immediately goes to False\n",
    "    # Then... check if the target and at least one read disagree ->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = BFP_LIST[0]\n",
    "left = test.iloc[:, 1:4]\n",
    "right = test.iloc[:, 0]\n",
    "left, right = left.align(right, axis=1, copy=False)\n",
    "np.where( (left!= right).any(axis=1), True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Length Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isSingleSNP(df, idx):\n",
    "    pass\n",
    "\n",
    "def isSingleDel(df, cov, idx): # Checks if read has only one indel.\n",
    "    # Assumes it's a del row.\n",
    "    def check_del_left(df, idx, cov):\n",
    "        if idx == 0: return False\n",
    "        return (df.iloc[idx-1, 1:cov+1] == 45).any()\n",
    "    def check_del_right(df, idx, cov):\n",
    "        if idx == len(df) - 1: return False\n",
    "        return ((df.iloc[idx+1, 1:cov+1] == 45).any())\n",
    "\n",
    "    try:\n",
    "        df.iloc[idx, -1] = True if ( check_del_right(df, idx, cov) and check_del_left(df, idx, cov)) else False\n",
    "    except:\n",
    "        print(\"is single index uh oh \")\n",
    "    # isMulti if a single 45 is present left or right.\n",
    "    \n",
    "def isSingleIns(df, idx): # Checks if target has only one indel.\n",
    "    def check_right(df, idx):\n",
    "        if idx == len(df) - 1: return False\n",
    "        return (df.iloc[idx+1, 0] == 45)\n",
    "    def check_left(df, idx):\n",
    "        if idx == 0: return False\n",
    "        return (df.iloc[idx-1, 0] == 45)\n",
    "    # print(idx)\n",
    "    df.iloc[idx, -1] = True if (check_right(df, idx) and check_left(df, idx)) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variation_length(df, cov):\n",
    "    df['is_single'] = pd.Series([True for _ in range(len(df))])\n",
    "\n",
    "    dels = df.iloc[np.where(( df[['is_indel', 'is_ins']] == [True, False] ).all(axis=1) == True)[0], :]\n",
    "    to_check = dels.index.to_list()\n",
    "    if not to_check == []:\n",
    "        print(to_check)\n",
    "        for i in to_check:\n",
    "            isSingleDel( df, cov, i )\n",
    "\n",
    "    ins = df.iloc[np.where((df[['is_indel', 'is_ins']] == [True, True]).all(axis=1) == True)[0], :]\n",
    "    to_check = ins.index.to_list()\n",
    "    if not to_check:\n",
    "        for i in to_check:\n",
    "            isSingleIns(df, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Engineered Features to RFP and BFP pd.DataFrame objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df, cov, indel_parse=False, rfp=False):\n",
    "    if rfp:\n",
    "        print('RFP-specific parsing currently inactivated.')\n",
    "    # if rfp:\n",
    "    #     focus = [i for i in range(1, cov+1)]\n",
    "    #     focus.append(2*cov+2) # contig?\n",
    "    #     nan_mask = df.iloc[:, focus][df != 45]\n",
    "    \n",
    "    if indel_parse:\n",
    "        nan_mask = df.iloc[:, 0:cov+1][df!=45]\n",
    "        df['is_indel'] = np.where(nan_mask.count(axis = 1) == cov+1, False, True) #cov + 1 because targ/contig included\n",
    "        \n",
    "    # isSNP, isIns, isDel\n",
    "    add_variation_type(df, cov)\n",
    "    \n",
    "    # isSingle, isMulti\n",
    "    add_variation_length(df, cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_progress(n, each=False):\n",
    "    if each:\n",
    "        print(n, end=\"\\r\")\n",
    "    else:\n",
    "        if (n % 3551 == 0): print(f'{n / 355104:.0%}', end='\\r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/david/Desktop/The_Coding_Journey/Artificial Intelligence/NeuroToolBox/mutalib/features.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000036?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m bfp\u001b[39m.\u001b[39mempty: \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000036?line=2'>3</a>\u001b[0m get_progress(n, each\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000036?line=3'>4</a>\u001b[0m add_features(bfp, get_cov(bfp))\n",
      "\u001b[1;32m/Users/david/Desktop/The_Coding_Journey/Artificial Intelligence/NeuroToolBox/mutalib/features.ipynb Cell 13\u001b[0m in \u001b[0;36madd_features\u001b[0;34m(df, cov, indel_parse, rfp)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000036?line=10'>11</a>\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mis_indel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(nan_mask\u001b[39m.\u001b[39mcount(axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m cov\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m) \u001b[39m#cov + 1 because targ/contig included\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000036?line=12'>13</a>\u001b[0m \u001b[39m# isSNP, isIns, isDel\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000036?line=13'>14</a>\u001b[0m add_variation_type(df, cov)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000036?line=15'>16</a>\u001b[0m \u001b[39m# isSingle, isMulti\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000036?line=16'>17</a>\u001b[0m add_variation_length(df, cov)\n",
      "\u001b[1;32m/Users/david/Desktop/The_Coding_Journey/Artificial Intelligence/NeuroToolBox/mutalib/features.ipynb Cell 13\u001b[0m in \u001b[0;36madd_variation_type\u001b[0;34m(df, cov)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000036?line=33'>34</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_row_variation\u001b[39m(df, cov):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000036?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mwhere( (df\u001b[39m.\u001b[39miloc[:, \u001b[39m1\u001b[39m:cov\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcompare(df\u001b[39m.\u001b[39msqueeze(df\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]), keep_shape\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\u001b[39m.\u001b[39many(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), \u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000036?line=36'>37</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mis_snp\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere( df[\u001b[39m'\u001b[39m\u001b[39mis_indel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m, check_row_variation(df, cov), \u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/Users/david/Desktop/The_Coding_Journey/Artificial Intelligence/NeuroToolBox/mutalib/features.ipynb Cell 13\u001b[0m in \u001b[0;36madd_variation_type.<locals>.check_row_variation\u001b[0;34m(df, cov)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000036?line=33'>34</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_row_variation\u001b[39m(df, cov):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000036?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mwhere( (df\u001b[39m.\u001b[39miloc[:, \u001b[39m1\u001b[39m:cov\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcompare(df\u001b[39m.\u001b[39;49msqueeze(df\u001b[39m.\u001b[39;49miloc[:, \u001b[39m0\u001b[39;49m]), keep_shape\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\u001b[39m.\u001b[39many(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), \u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/generic.py:974\u001b[0m, in \u001b[0;36mNDFrame.squeeze\u001b[0;34m(self, axis)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m    871\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msqueeze\u001b[39m(\u001b[39mself\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    872\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[39m    Squeeze 1 dimensional axis objects into scalars.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[39m    1\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 974\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_AXIS_LEN) \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_axis_number(axis),)\n\u001b[1;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[\n\u001b[1;32m    976\u001b[0m         \u001b[39mtuple\u001b[39m(\n\u001b[1;32m    977\u001b[0m             \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m i \u001b[39min\u001b[39;00m axis \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(a) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    978\u001b[0m             \u001b[39mfor\u001b[39;00m i, a \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[1;32m    979\u001b[0m         )\n\u001b[1;32m    980\u001b[0m     ]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/generic.py:550\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m    547\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_axis_number\u001b[39m(\u001b[39mcls\u001b[39m, axis: Axis) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[1;32m    549\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_AXIS_TO_AXIS_NUMBER[axis]\n\u001b[1;32m    551\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo axis named \u001b[39m\u001b[39m{\u001b[39;00maxis\u001b[39m}\u001b[39;00m\u001b[39m for object type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Series'"
     ]
    }
   ],
   "source": [
    "for n, bfp in enumerate(BFP_LIST):\n",
    "    if bfp.empty: continue\n",
    "    get_progress(n, each=True)\n",
    "    add_features(bfp, get_cov(bfp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to facilitate feature-type filtering -> will be used to grab specific rows for training\n",
    "def pd_filter(df, columns, conditions, all=True):\n",
    "    columns_to_filter_by = df[columns]\n",
    "    if all:\n",
    "        return df.iloc[np.where( (columns_to_filter_by == conditions).all(axis=1))[0]]\n",
    "    else:\n",
    "        return df.iloc[np.where( (columns_to_filter_by == conditions).any(axis=1))[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_ASSEMBLY_MATRICES = 355104\n",
    "TOTAL_SAMPLES = TOTAL_ASSEMBLY_MATRICES * 50\n",
    "\n",
    "PERCENT_RED = 0.4\n",
    "PERCENT_BLUE = 0.6\n",
    "\n",
    "PERCENT_Z = 0.3\n",
    "PERCENT_Y = 0.5\n",
    "PERCENT_REGULAR = 0.2\n",
    "\n",
    "# To change as more features are added\n",
    "SAMPLE_SHAPE = (14)\n",
    "LABEL_SHAPE = (5)\n",
    "\n",
    "COUNT_MAPPING = {65 : 0, 67 : 0, 71 : 2, 84: 3, 45 : 4,}\n",
    "\n",
    "PROB_MAPPING = dict(zip([65, 67, 71, 84, 45], [5, 6, 7, 8, 9]))\n",
    "\n",
    "CATEGORY_MAPPING = dict(zip(['is_snp', 'is_ins', 'is_single', 'is_rfp'], [0, 1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query by Quality Score... then query by ground truth and read.\n",
    "CEM_INDELS = load( open('pickle/cem_indels_tensor.pickle', 'rb'))\n",
    "CEM_SNIPS = load( open('pickle/cem_snips_tensor.pickle', 'rb'))\n",
    "\n",
    "QADJ_INDELS = 0\n",
    "QADJ_SNIPS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHRED to ERROR RATE\n",
    "def convert_to_epsilon(nuc, zero_shifted_quality, indel=True):\n",
    "    database = QADJ_INDELS if indel else QADJ_SNIPS\n",
    "    return database[nuc][zero_shifted_quality]\n",
    "    \n",
    "# PHRED to CONDITIONAL SEQ ERROR\n",
    "def convert_to_cond_seq_error(nuc, ground_truth, zero_shifted_quality, indel=True):\n",
    "    database = CEM_INDELS if indel else CEM_SNIPS\n",
    "    cond_seq_error = database[zero_shifted_quality][PROB_MAPPING[nuc], PROB_MAPPING[ground_truth]]\n",
    "    return cond_seq_error * convert_to_epsilon(nuc, zero_shifted_quality, indel=indel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_df_run(df, all_samples, all_labels, reads_max, rfp=False, enforce_cov = False, cov_min=4):\n",
    "    if df.empty: return \n",
    "    cov = get_cov(df)\n",
    "    if enforce_cov and (cov < cov_min): return\n",
    "\n",
    "    reads_idxs = [i for i in range(1, cov+1)]\n",
    "    \n",
    "    if cov > 4: \n",
    "        reads_to_use = np.random.sample(reads_idxs, reads_max)\n",
    "    else:\n",
    "        reads_to_use = reads_idxs\n",
    "    # reads = [f'read{n}' for n in reads_to_use]\n",
    "    \n",
    "    # Get SNPs only\n",
    "    snps = pd_filter(df, 'is_snp', True)\n",
    "    \n",
    "    # Get Y conflicts only\n",
    "    ins = pd_filter(df, 'is_ins', True)\n",
    "    dels = pd_filter(df, ['is_indel', 'is_ins'], [True, False])\n",
    "    \n",
    "    # Get regulars?\n",
    "    def extend_data(s, l):\n",
    "        all_samples.extend(s)\n",
    "        all_labels.extend(l)\n",
    "    \n",
    "    # Actually update it\n",
    "    s, l = sample_label_generator(df, snps, cov, reads_to_use, all_samples, all_labels, snps=True)\n",
    "    extend_data(s, l)\n",
    "    \n",
    "    s, l = sample_label_generator(df, ins, cov, reads_to_use, ins=True)\n",
    "    extend_data(s, l)\n",
    "    \n",
    "    s, l = sample_label_generator(df, dels, cov, reads_to_use)\n",
    "    extend_data(s, l)\n",
    "\n",
    "def sample_label_generator(df, filtered_data, cov, reads_to_use, rfp=False, snps=False, ins=False):\n",
    "    samples = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(len(filtered_data)):\n",
    "        sample = torch.empty(SAMPLE_SHAPE)\n",
    "        label = torch.zeros(LABEL_SHAPE)\n",
    "        count = np.zeros(5)\n",
    "        prob = np.ones(5)\n",
    "        \n",
    "        if snps:\n",
    "            category = np.array([1, 0, 0, 1]) if rfp else np.array([1, 0, 0, 0])\n",
    "        elif ins:\n",
    "            category = np.array([0, 1, 0, 1]) if rfp else np.array([0, 1, 0, 0])\n",
    "        else:\n",
    "            category = np.array([0, 0, 0, 1]) if rfp else np.array([0, 0, 0, 0])\n",
    "        \n",
    "        # Row by row...\n",
    "        ground = df['target'].iloc[i]\n",
    "        truth = df['contig'].iloc[i] if rfp else ground\n",
    "            \n",
    "        for r in reads_to_use:\n",
    "            nuc = df[f'read{r}'].iloc[i]\n",
    "            quality = df[f'q{r}'].iloc[i]\n",
    "            if nuc == ground:\n",
    "                prob[PROB_MAPPING.get(nuc)] *= (1 - convert_to_epsilon('snp', nuc, quality) )\n",
    "            else: \n",
    "                prob[PROB_MAPPING.get(nuc)] *= convert_to_epsilon('snp', nuc, quality) * convert_to_cond_seq_error('snp', nuc, ground, quality)\n",
    "            count[PROB_MAPPING.get(nuc)] += 1\n",
    "        if df['is_single'].iloc[i] is True:\n",
    "            category[CATEGORY_MAPPING.get('is_single')] = 1\n",
    "            \n",
    "        # Update sample, label\n",
    "        sample[0:5] = count\n",
    "        sample[5:10] = prob\n",
    "        sample[10:14] = category\n",
    "        label[PROB_MAPPING.get(truth)] = 1\n",
    "        samples.append(sample)\n",
    "        labels.append(label)\n",
    "        \n",
    "    return samples, labels\n",
    "\n",
    "def get_data(df_list, rfp=False, enforce_cov=False, cov_min=4, reads_max=3, multiple_sizes=False, multiple_sampling=False, random_select=False):\n",
    "    all_samples = []\n",
    "    all_labels = []\n",
    "    \n",
    "    percent_of_total = PERCENT_BLUE\n",
    "    if rfp: percent_of_total = PERCENT_RED\n",
    "    \n",
    "    size = percent_of_total * TOTAL_ASSEMBLY_MATRICES\n",
    "    one_percent = 0.01 * size\n",
    "    \n",
    "    max_z = PERCENT_Z * TOTAL_SAMPLES\n",
    "    max_y = PERCENT_Y * TOTAL_SAMPLES\n",
    "    max_reg = PERCENT_REGULAR * TOTAL_SAMPLES\n",
    "    \n",
    "    count_z, count_y, count_reg = 0, 0, 0\n",
    "    \n",
    "    if random_select:\n",
    "        random_idxs = np.random.permutation(TOTAL_ASSEMBLY_MATRICES)\n",
    "        \n",
    "        for n, idx in enumerate(random_idxs):\n",
    "            if (n % one_percent == 0): print(f'{n / size:.0%}', end='\\r') \n",
    "            df = df_list[idx]\n",
    "            single_df_run(df, all_samples, all_labels, reads_max)\n",
    "            \n",
    "    return all_samples, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'is_snp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_snp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/david/Desktop/The_Coding_Journey/Artificial Intelligence/NeuroToolBox/mutalib/features.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=0'>1</a>\u001b[0m samples, labels \u001b[39m=\u001b[39m get_data(BFP_LIST, random_select\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32m/Users/david/Desktop/The_Coding_Journey/Artificial Intelligence/NeuroToolBox/mutalib/features.ipynb Cell 19\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(df_list, rfp, enforce_cov, cov_min, reads_max, multiple_sizes, multiple_sampling, random_select)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=97'>98</a>\u001b[0m         \u001b[39mif\u001b[39;00m (n \u001b[39m%\u001b[39m one_percent \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m): \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mn \u001b[39m/\u001b[39m size\u001b[39m:\u001b[39;00m\u001b[39m.0%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m'\u001b[39m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=98'>99</a>\u001b[0m         df \u001b[39m=\u001b[39m df_list[idx]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=99'>100</a>\u001b[0m         single_df_run(df, all_samples, all_labels, reads_max)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=101'>102</a>\u001b[0m \u001b[39mreturn\u001b[39;00m all_samples, all_labels\n",
      "\u001b[1;32m/Users/david/Desktop/The_Coding_Journey/Artificial Intelligence/NeuroToolBox/mutalib/features.ipynb Cell 19\u001b[0m in \u001b[0;36msingle_df_run\u001b[0;34m(df, all_samples, all_labels, reads_max, rfp, enforce_cov, cov_min)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=10'>11</a>\u001b[0m     reads_to_use \u001b[39m=\u001b[39m reads_idxs\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=11'>12</a>\u001b[0m \u001b[39m# reads = [f'read{n}' for n in reads_to_use]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=12'>13</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=13'>14</a>\u001b[0m \u001b[39m# Get SNPs only\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=14'>15</a>\u001b[0m snps \u001b[39m=\u001b[39m pd_filter(df, \u001b[39m'\u001b[39;49m\u001b[39mis_snp\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=16'>17</a>\u001b[0m \u001b[39m# Get Y conflicts only\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=17'>18</a>\u001b[0m ins \u001b[39m=\u001b[39m pd_filter(df, \u001b[39m'\u001b[39m\u001b[39mis_ins\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/Users/david/Desktop/The_Coding_Journey/Artificial Intelligence/NeuroToolBox/mutalib/features.ipynb Cell 19\u001b[0m in \u001b[0;36mpd_filter\u001b[0;34m(df, columns, conditions, all)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpd_filter\u001b[39m(df, columns, conditions, \u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=2'>3</a>\u001b[0m     columns_to_filter_by \u001b[39m=\u001b[39m df[columns]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/david/Desktop/The_Coding_Journey/Artificial%20Intelligence/NeuroToolBox/mutalib/features.ipynb#ch0000035?line=4'>5</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39miloc[np\u001b[39m.\u001b[39mwhere( (columns_to_filter_by \u001b[39m==\u001b[39m conditions)\u001b[39m.\u001b[39mall(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_snp'"
     ]
    }
   ],
   "source": [
    "samples, labels = get_data(BFP_LIST, random_select=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pd_update_method(x):\n",
    "    sample = torch.empty(SAMPLE_SHAPE)\n",
    "    label = torch.zeros(LABEL_SHAPE)\n",
    "    count = np.zeros(5)\n",
    "    prob = np.ones(5)\n",
    "    category = np.array([1, 0, 0, 1]) if rfp else np.array([1, 0, 0, 0])\n",
    "    \n",
    "    # Row by row...\n",
    "    ground = df['target']\n",
    "    truth = df['contig']\n",
    "    for r in reads_to_use:\n",
    "        nuc = df[f'read{r}']\n",
    "    quality = df[f'q{r}']\n",
    "    if nuc == ground:\n",
    "        prob[PROB_MAPPING.get(nuc)] *= (1 - convert_to_epsilon('snp', nuc, quality) )\n",
    "    else: \n",
    "        prob[PROB_MAPPING.get(nuc)] *= convert_to_epsilon('snp', nuc, quality) * convert_to_cond_seq_error('snp', nuc, ground, quality)\n",
    "    count[PROB_MAPPING.get(nuc)] += 1\n",
    "    if df['is_single'] is True:\n",
    "        category[CATEGORY_MAPPING.get('is_single')] = 1\n",
    "    return [sample, label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ecc7f9766571fb1273a2ad528061ce289f5339aed43b6b7c9419d8efc8c0d2ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
